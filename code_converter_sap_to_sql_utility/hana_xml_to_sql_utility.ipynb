{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64f5b064-9b7f-4922-8446-e575a4c9c886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ONLY USE THIS UTILITY WITH XML THAT CONTAIN MULTIPLE TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "535fad45-ee0d-4b7f-9316-a1482be6f43a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4d7d040c-128d-4ca3-9e7e-83a7920b90dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c909ffb-681d-4596-ad90-78488d8a3995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import xmltodict\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03319a71-bc44-4c61-863b-7babf931686c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT_STR = \"SELECT \"\n",
    "GROUP_STR = \"GROUP BY ALL\"\n",
    "AGG_BEHAV_KEY = \"@aggregationType\"\n",
    "FILTER_EXP_KEY = \"filter\"\n",
    "ELEM_FILTER_KEY = \"elementFilter\"\n",
    "LAYOUT_KEY = \"layout\"\n",
    "ELEM_KEY = \"viewAttributes\"\n",
    "INPUT_KEY = \"input\"\n",
    "MAPPING_KEY = \"mapping\"\n",
    "NAME_KEY = \"@id\"\n",
    "TEXT_KEY = \"#text\"\n",
    "VIEWNODE_KEY = \"@node\"\n",
    "ENTITY_KEY = \"@node\"\n",
    "LEFTINP_KEY = \"@leftInput\"\n",
    "RIGHTINP_KEY = \"@rightInput\"\n",
    "JOINTYP_KEY = \"@joinType\"\n",
    "JOINATR_KEY = \"joinAttribute\"\n",
    "SRC_KEY = \"@source\"\n",
    "TRGT_KEY = \"@target\"\n",
    "CALCS_KEY = \"calculatedViewAttributes\"\n",
    "CALC_KEY = \"calculatedViewAttribute\"\n",
    "FORMULA_KEY = \"formula\"\n",
    "YCOORD_KEY = \"@yCoordinate\"\n",
    "XSITYP_KEY = \"@xsi:type\"\n",
    "DATATYPE_KEY = \"@datatype\"\n",
    "\n",
    "all_queries = dict()\n",
    "join_node_tbl_alias = dict()\n",
    "\n",
    "\n",
    "def has_inline_type(elem):\n",
    "    return DATATYPE_KEY in elem\n",
    "\n",
    "\n",
    "def is_num_type(elem):\n",
    "    if not has_inline_type(elem):\n",
    "        return False\n",
    "    return elem[DATATYPE_KEY] in [\n",
    "        \"NUMBER\",\n",
    "        \"INTEGER\",\n",
    "        \"DECIMAL\",\n",
    "        \"FLOAT\",\n",
    "        \"DOUBLE\",\n",
    "        \"REAL\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def cast_type(elem):\n",
    "    val = elem[FORMULA_KEY]\n",
    "    datatype = elem[DATATYPE_KEY]\n",
    "    if (\n",
    "        datatype == \"DATE\"\n",
    "        and len(re.findall(\"date[\\r\\n\\s]*\\(.*?\\)\", val, flags=re.IGNORECASE)) == 0\n",
    "    ):\n",
    "        val = \"try_to_date(\" + val.replace(\"+\", \" || \") + \", 'yyyyMMdd')\"\n",
    "    elif datatype == \"TIMESTAMP\":\n",
    "        val = \"TO_TIMESTAMP_NTZ(\" + val.replace(\"+\", \" || \") + \", 'yyyyMMddHHmmss')\"\n",
    "    return val\n",
    "\n",
    "def lower_except_quotes(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    def preserve_case(match):\n",
    "        quoted = match.group(1)\n",
    "        unquoted = match.group(2)\n",
    "        return quoted if quoted else unquoted.lower()\n",
    "    pattern = re.compile(r\"('.*?')|([^']+)\")\n",
    "    return ''.join(\n",
    "        preserve_case(m) if isinstance(m.group(2), str) else m.group(1) for m in pattern.finditer(text)\n",
    "    )\n",
    "def is_list(obj):\n",
    "    return isinstance(obj, list)\n",
    "\n",
    "\n",
    "def newline_beatify(s):\n",
    "    return re.sub(\"((?:[^,]*,){1})\", r\"\\1\\n\", s, 0, re.DOTALL)\n",
    "\n",
    "\n",
    "def is_elem_aggregated(elem):\n",
    "    if (\n",
    "        AGG_BEHAV_KEY not in elem\n",
    "        or elem[AGG_BEHAV_KEY] == \"NONE\"\n",
    "        or elem[AGG_BEHAV_KEY] == FORMULA_KEY\n",
    "    ):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def replace_dict(query, rep_dict):\n",
    "    mod_str = str(query)\n",
    "    for repl, value in rep_dict.items():\n",
    "        mod_str = mod_str.replace(repl, value)\n",
    "    return mod_str\n",
    "\n",
    "\n",
    "def repl_sap_func(s):\n",
    "    s = s.replace(\"if( \",\"IF(\")\n",
    "    # REPLACE SAP NOW() with CURRENT_TIMESTAMP\n",
    "    matches = re.findall(\"now\\(.*?\\)\", s, flags=re.IGNORECASE)\n",
    "    match_dict = {item: \"current_timestamp\" for item in matches}\n",
    "    mod_str = replace_dict(s, match_dict)\n",
    "    # REPLACE isNull with IS NULL\n",
    "    matches = re.findall(\"isnull[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: re.findall(r\"\\((.*?)\\)\", item)[0] + \" is null\" for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE IF \n",
    "    matches = re.findall(\"IF[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"if(\" + re.findall(r\"\\((.*?)\\)\", item)[0] + \")\" for item in matches\n",
    "    }\n",
    "    mod_str = (\n",
    "        replace_dict(mod_str, match_dict)\n",
    "    ).replace('\"', '')\n",
    "    # REPLACE CASE with DECODE\n",
    "    matches = re.findall(\"case[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"decode(\" + re.findall(r\"\\((.*?)\\)\", item)[0] + \")\" for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict).replace(\"case(\", \"DECODE(\")\n",
    "    # REPLACE MIDSTR with SUBSTRING\n",
    "    matches = re.findall(\"midstr[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"substring(\" + re.findall(r\"\\((.*?)\\)\", item)[0] + \")\" for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE LEFTSTR with LEFT\n",
    "    matches = re.findall(\"leftstr[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"left(\" + re.findall(r\"\\((.*?)\\)\", item)[0] + \")\" for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE RIGHTSTR with RIGHT\n",
    "    matches = re.findall(\"rightstr[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"right(\" + re.findall(r\"\\((.*?)\\)\", item)[0] + \")\" for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE MATCH with REGEXP_LIKE\n",
    "    matches = re.findall(\"match[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"rlike(\"\n",
    "        + re.findall(r\"\\((.*?)\\)\", item)[0].replace(\"*\", \".*\")\n",
    "        + \")\"\n",
    "        for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE SAP DATE() with DATE with format\n",
    "    matches = re.findall(\"^date[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"date(\" + re.findall(r\"\\((.*?)\\)\", item)[0] + r\",\\'yyyyMMdd\\')\"\n",
    "        for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE SAP DAYSBETWEEN() with DATE with format\n",
    "    matches = re.findall(\"daysbetween[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"datediff(day,\" + re.findall(r\"\\((.*?)\\)\", item)[0] + r\",\\'yyyyMMdd\\')\"\n",
    "        for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE SAP FORMAT() with to_string\n",
    "    matches = re.findall(\"format[\\r\\n\\s]*\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: \"cast(\" + re.findall(r\"\\((.*?)\\)\", item)[0] + \" as string)\"\n",
    "        for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE SAP STRING() with ::STRING\n",
    "    matches = re.findall(\"string\\(.*?\\)\", mod_str, flags=re.IGNORECASE)\n",
    "    match_dict = {\n",
    "        item: re.findall(r\"\\((.*?)\\)\", item)[0] + \"::string\" for item in matches\n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    # REPLACE SAP IN() with IN\n",
    "    matches = re.findall(  \n",
    "        r'in\\(\\s*([^)]*?)\\s*\\)', mod_str,flags=re.IGNORECASE  \n",
    "    )  \n",
    "    match_dict = {  \n",
    "        item: f\"{item.split(',')[0] if item.split('(')[0] not in ('left','right') else item.split(',')[0] + ',' + item.split(',')[1]} IN ({', '.join([v.strip().replace(')', '') for v in (item.split(',')[1:] if item.split('(')[0] not in ('left','right') else item.split(',')[2:])])}\"   if item.split('(')[0] not in (\"ltrim\") else item + ') in ('\n",
    "        for item in matches \n",
    "    }\n",
    "    mod_str = replace_dict(mod_str, match_dict)\n",
    "    return mod_str\n",
    "\n",
    "\n",
    "def get_filter_exp(node):\n",
    "    if FILTER_EXP_KEY in node.keys():\n",
    "        return \"WHERE \" + node[FILTER_EXP_KEY]\n",
    "    elif ELEM_FILTER_KEY in node.keys():\n",
    "        elem_filter = node[ELEM_FILTER_KEY]\n",
    "\n",
    "        if is_list(elem_filter):\n",
    "            where_str = \"WHERE \"\n",
    "            for elem_f in elem_filter:\n",
    "                if elem_f[\"valueFilter\"][XSITYP_KEY] == \"Column:SingleValueFilter\":\n",
    "                    where_str = (\n",
    "                        where_str\n",
    "                        + \"\\n\"\n",
    "                        + '\"'\n",
    "                        + elem_f[\"@elementName\"]\n",
    "                        + \"\\\"='\"\n",
    "                        + elem_f[\"valueFilter\"][\"@value\"]\n",
    "                        + \"'\\nAND\"\n",
    "                    )\n",
    "                elif elem_f[\"valueFilter\"][XSITYP_KEY] == \"Column:ListValueFilter\":\n",
    "                    operands = (\n",
    "                        elem_f[\"valueFilter\"][\"operands\"]\n",
    "                        if is_list(elem_f[\"valueFilter\"][\"operands\"])\n",
    "                        else list(elem_f[\"valueFilter\"][\"operands\"])\n",
    "                    )\n",
    "                    operands = [\"'\" + op[\"@value\"] + \"'\" for op in operands]\n",
    "                    in_str = \" IN (\" + \",\".join(operands) + \")\"\n",
    "                    where_str = (\n",
    "                        where_str + \"\\n\" + '\"' + elem_f[\"@elementName\"] + '\"' + in_str\n",
    "                    )\n",
    "            return where_str\n",
    "        else:\n",
    "            if elem_filter[\"valueFilter\"][XSITYP_KEY] == \"Column:SingleValueFilter\":\n",
    "                return (\n",
    "                    \"WHERE \"\n",
    "                    + '\"'\n",
    "                    + elem_filter[\"@elementName\"]\n",
    "                    + \"\\\"='\"\n",
    "                    + elem_filter[\"valueFilter\"][\"@value\"]\n",
    "                    + \"'\"\n",
    "                )\n",
    "            elif elem_filter[\"valueFilter\"][XSITYP_KEY] == \"Column:ListValueFilter\":\n",
    "                operands = (\n",
    "                    elem_filter[\"valueFilter\"][\"operands\"]\n",
    "                    if is_list(elem_filter[\"valueFilter\"][\"operands\"])\n",
    "                    else list(elem_filter[\"valueFilter\"][\"operands\"])\n",
    "                )\n",
    "                operands = [\"'\" + op[\"@value\"] + \"'\" for op in operands]\n",
    "                in_str = \" IN (\" + \",\".join(operands) + \")\"\n",
    "                return \"WHERE \" + '\"' + elem_filter[\"@elementName\"] + '\"' + in_str\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def dataSources(s):\n",
    "    for node in full_xml_nodes[\"dataSources\"][\"DataSource\"]:\n",
    "        if isinstance(node,str):\n",
    "            datasource_nodes = [(full_xml_nodes[\"dataSources\"][\"DataSource\"][\"@id\"])]\n",
    "            return str(datasource_nodes)    \n",
    "        if node[\"@id\"] in node:\n",
    "            datasource_nodes = [node]\n",
    "            return str(datasource_nodes)\n",
    "        else:\n",
    "            datasource_nodes = [s]\n",
    "            return str(datasource_nodes).replace(\"#\", \"\")\n",
    "            \n",
    "\n",
    "\n",
    "def get_obj(s):\n",
    "    return s.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "def get_from_part(node):\n",
    "    from_part = \"from \" + dataSources(node[VIEWNODE_KEY])\n",
    "    return from_part.replace(\"['\", \"\").replace(\"']\", \"\")\n",
    "\n",
    "\n",
    "def type_of_join(s):\n",
    "    if \"leftouter\" in s.lower():\n",
    "        return \" left join \"\n",
    "    elif \"rightouter\" in s.lower():\n",
    "        return \" right join \"\n",
    "    elif \"inner\" in s.lower() or \"referential\" in s.lower():\n",
    "        return \" inner join \"\n",
    "\n",
    "\n",
    "def get_cols_from_map(mp, reverse=True, fromnode=None):\n",
    "    res = []\n",
    "\n",
    "    if fromnode == \"JoinNode\":\n",
    "        if reverse:\n",
    "            for k, v in mp.items():\n",
    "                if v.split(\".\")[-1].strip().lower() == k.strip().lower():\n",
    "                    res.append(v)\n",
    "                else:\n",
    "                    res.append(v + \" \" + k)\n",
    "        else:\n",
    "            for k, v in mp.items():\n",
    "                if v.split(\".\")[-1].strip().lower() == k.strip().lower():\n",
    "                    res.append(k)\n",
    "                else:\n",
    "                    res.append(k + \" \" + v)\n",
    "    else:\n",
    "        if reverse:\n",
    "            for k, v in mp.items():\n",
    "                if v.strip().lower() == k.strip().lower():\n",
    "                    res.append(v)\n",
    "                else:\n",
    "                    res.append(v + \" \" + k)\n",
    "        else:\n",
    "            for k, v in mp.items():\n",
    "                if v.strip().lower() == k.strip().lower():\n",
    "                    res.append(k)\n",
    "                else:\n",
    "                    res.append(k + \" \" + v)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_calc_cols_from_map(mp, is_join=False):\n",
    "    if not is_join:\n",
    "        res = []\n",
    "        for k, v in mp.items():\n",
    "            if v.strip().lower() == k.strip().lower():\n",
    "                res.append(v)\n",
    "            else:\n",
    "                res.append(v + \" AS \" + k)\n",
    "    elif is_join:\n",
    "        res = {}\n",
    "        for k, v in mp.items():\n",
    "            v = (\n",
    "                v.strip()\n",
    "            )  # Clean the value by removing newlines and stripping whitespace\n",
    "            if v.lower() == k.strip().lower():\n",
    "                res[k] = v  # If they match, use the cleaned value as is\n",
    "            else:\n",
    "                res[k] = v + \" AS \"  # Otherwise, append ' AS k' to the cleaned value\n",
    "    return res\n",
    "\n",
    "\n",
    "def generate_on_part(leftcols, rightcols, leftalias, rightalias):\n",
    "    on_part = \"\"\n",
    "    if is_list(leftcols):\n",
    "        on_cols = [\n",
    "            leftalias\n",
    "            + \".\"\n",
    "            + str(leftcols[x][\"@source\"])\n",
    "            + \" = \"\n",
    "            + rightalias\n",
    "            + \".\"\n",
    "            + str(rightcols[x][\"@source\"])\n",
    "            for x in range(len(leftcols))\n",
    "                if leftcols[x][\"@target\"] in [y[\"@target\"] for y in rightcols]\n",
    "        ]\n",
    "        on_part = \"ON \" + \" AND\\n\".join(on_cols)\n",
    "    elif isinstance(leftcols, str):\n",
    "        on_part = (\n",
    "            \"ON \" + leftalias + \".\" + leftcols + \" = \" + rightalias + \".\" + rightcols\n",
    "        )\n",
    "    return on_part\n",
    "\n",
    "\n",
    "def is_calc_col(col):\n",
    "    if col is not None:\n",
    "        if \"calculatedViewAttribute\" in col:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_calc_columns(elem):\n",
    "    mapping = dict()\n",
    "    if isinstance(elem[CALC_KEY], dict):\n",
    "        if has_inline_type(elem[CALC_KEY]):\n",
    "            mapping[elem[CALC_KEY][NAME_KEY]] = cast_type(elem[CALC_KEY])\n",
    "        else:\n",
    "            mapping[elem[CALC_KEY][NAME_KEY]] = elem[CALC_KEY][FORMULA_KEY]\n",
    "    elif is_list(elem[CALC_KEY]):\n",
    "        for x in range(len(elem[CALC_KEY])):\n",
    "            if has_inline_type(elem[CALC_KEY][x]):\n",
    "                mapping[elem[CALC_KEY][x][NAME_KEY]] = cast_type(elem[CALC_KEY][x])\n",
    "            else:\n",
    "                mapping[elem[CALC_KEY][x][NAME_KEY]] = elem[CALC_KEY][x][FORMULA_KEY]\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def wrap_agg(s, fun):\n",
    "    return fun + \"(\" + s + \") AS \"\n",
    "\n",
    "\n",
    "def generate_full_join(node, node_name):\n",
    "    all_tbls_alias = dict()\n",
    "    all_tbls_alias_repl = dict()\n",
    "    all_tbls_alias_repl1 = dict()\n",
    "    mapping_left = dict()\n",
    "    mapping_right = dict()\n",
    "    full_join = \"FROM\\n\"\n",
    "    if is_list(node[INPUT_KEY]):\n",
    "        i = 0\n",
    "        for j in range(len(node[INPUT_KEY]) - 1):\n",
    "            i += 1\n",
    "            all_tbls_alias.setdefault((node[INPUT_KEY][j][VIEWNODE_KEY]), \"t\" + str(i))\n",
    "            i += 1\n",
    "            all_tbls_alias.setdefault(\n",
    "                (node[INPUT_KEY][i - 1][VIEWNODE_KEY]), \"t\" + str(i)\n",
    "            )\n",
    "            if isinstance(node[INPUT_KEY][j][MAPPING_KEY], list):\n",
    "                for m in range(len(node[INPUT_KEY][j][MAPPING_KEY])):\n",
    "                    mapping_left[node[INPUT_KEY][j][MAPPING_KEY][m]['@target']] =node[INPUT_KEY][j][MAPPING_KEY][m]['@source']\n",
    "            else:\n",
    "                mapping_left[node[INPUT_KEY][j][MAPPING_KEY]['@target']] = node[INPUT_KEY][j][MAPPING_KEY]['@source']\n",
    "            if isinstance(node[INPUT_KEY][i-1][MAPPING_KEY], list):\n",
    "                for n in range(len(node[INPUT_KEY][i-1][MAPPING_KEY])):\n",
    "                    mapping_right[node[INPUT_KEY][i-1][MAPPING_KEY][n]['@target']] = [node[INPUT_KEY][i-1][MAPPING_KEY][n]['@source']]\n",
    "            else:\n",
    "                mapping_right[node[INPUT_KEY][i-1][MAPPING_KEY]['@target']] = [node[INPUT_KEY][i-1][MAPPING_KEY]['@source']]\n",
    "            \n",
    "            if j == 0:\n",
    "                join_part = (\n",
    "                    node[INPUT_KEY][j][VIEWNODE_KEY]\n",
    "                    + \" \"\n",
    "                    + all_tbls_alias[node[INPUT_KEY][j][VIEWNODE_KEY]] \n",
    "                    + \"\\n\"\n",
    "                    + type_of_join(node[JOINTYP_KEY])\n",
    "                    + \"\\n\"\n",
    "                    + \n",
    "                    node[INPUT_KEY][i-1][VIEWNODE_KEY] \n",
    "                    + \" \"\n",
    "                    + all_tbls_alias[node[INPUT_KEY][i - 1][VIEWNODE_KEY]]\n",
    "                    + \"\\n\"\n",
    "                )\n",
    "            else:\n",
    "                join_part = (\n",
    "                    \"\\n\"\n",
    "                    + type_of_join(node[j][JOINTYP_KEY])\n",
    "                    + \"\\n\"\n",
    "                    + node[j][VIEWNODE_KEY]\n",
    "                    + \" \"\n",
    "                    + all_tbls_alias[node[j][VIEWNODE_KEY]]\n",
    "                    + \"\\n\"\n",
    "                )\n",
    "            \n",
    "            mapped_left = [{'@target': x['@name'], '@source': mapping_left[x['@name']]} for x in node[JOINATR_KEY]] if isinstance(node[JOINATR_KEY], list) else [{'@target': node[JOINATR_KEY]['@name'], '@source': mapping_left[node[JOINATR_KEY]['@name']]}]\n",
    "            mapped_right = [{'@target': x['@name'], '@source': mapping_right[x['@name']]} for x in node[JOINATR_KEY]] if isinstance(node[JOINATR_KEY], list) else [{'@target': node[JOINATR_KEY]['@name'], '@source': mapping_right[node[JOINATR_KEY]['@name']]}]\n",
    "  \n",
    "            on_part = generate_on_part(\n",
    "                mapped_left,\n",
    "                mapped_right,\n",
    "                all_tbls_alias[node[INPUT_KEY][j][VIEWNODE_KEY]],\n",
    "                all_tbls_alias[node[INPUT_KEY][i - 1][VIEWNODE_KEY]],\n",
    "            )\n",
    "            join_part = join_part + on_part\n",
    "            full_join = full_join + join_part\n",
    "        for k, v in all_tbls_alias.items():\n",
    "            all_tbls_alias_repl[k] = get_obj(k)\n",
    "            all_tbls_alias_repl1[get_obj(k)] = v\n",
    "        full_join = replace_dict(full_join, all_tbls_alias_repl)\n",
    "        join_node_tbl_alias.update({node_name: all_tbls_alias_repl1})\n",
    "    else:\n",
    "        leftalias = \"t1\"\n",
    "        rightalias = \"t2\"\n",
    "        all_tbls_alias.setdefault(node[VIEWNODE_KEY], leftalias)\n",
    "        all_tbls_alias.setdefault(node[VIEWNODE_KEY], rightalias)\n",
    "        join_part = (\n",
    "            node[VIEWNODE_KEY]\n",
    "            + \" \"\n",
    "            + leftalias\n",
    "            + \"\\n\"\n",
    "            + type_of_join(node[JOINTYP_KEY])\n",
    "            + \"\\n\"\n",
    "            + node[VIEWNODE_KEY]\n",
    "            + \" \"\n",
    "            + rightalias\n",
    "            + \"\\n\"\n",
    "        )\n",
    "        on_part = generate_on_part(\n",
    "            node[\"leftElementName\"], node[\"rightElementName\"], leftalias, rightalias\n",
    "        )\n",
    "        \n",
    "        join_part = join_part + on_part\n",
    "        full_join = full_join + join_part\n",
    "        for k, v in all_tbls_alias.items():\n",
    "            all_tbls_alias_repl[k] = get_obj(k)\n",
    "            all_tbls_alias_repl1[get_obj(k)] = v\n",
    "        full_join = replace_dict(full_join, all_tbls_alias_repl)\n",
    "    join_node_tbl_alias.update({node_name: all_tbls_alias_repl1})\n",
    "    return full_join\n",
    "\n",
    "\n",
    "def get_other_colmap(nodes, othercols, node_name) -> dict:\n",
    "    join_nodes = [x for x in nodes[INPUT_KEY] if MAPPING_KEY in x]\n",
    "    node_aliases = join_node_tbl_alias[node_name]\n",
    "    all_join_nodes = dict()\n",
    "    src_trgt_map = dict()\n",
    "    for item in join_nodes:\n",
    "        if VIEWNODE_KEY in item and is_list(item[MAPPING_KEY]):\n",
    "            for x in item[MAPPING_KEY]:\n",
    "                all_join_nodes.setdefault(\n",
    "                    x[TRGT_KEY],\n",
    "                    node_aliases[get_obj(item[VIEWNODE_KEY])] + \".\" + x[SRC_KEY],\n",
    "                )\n",
    "        elif VIEWNODE_KEY in item and not is_list(item[MAPPING_KEY]):\n",
    "            all_join_nodes.setdefault(\n",
    "                item[MAPPING_KEY][TRGT_KEY],\n",
    "                node_aliases[get_obj(item[VIEWNODE_KEY])]\n",
    "                + \".\"\n",
    "                + item[MAPPING_KEY][SRC_KEY],\n",
    "            )\n",
    "        elif ENTITY_KEY in item and is_list(item[MAPPING_KEY]):\n",
    "            for x in item[MAPPING_KEY]:\n",
    "                all_join_nodes.setdefault(\n",
    "                    x[TRGT_KEY],\n",
    "                    node_aliases[get_obj(item[ENTITY_KEY])] + \".\" + x[SRC_KEY],\n",
    "                )\n",
    "        elif ENTITY_KEY in item and not is_list(item[MAPPING_KEY]):\n",
    "            all_join_nodes.setdefault(\n",
    "                item[MAPPING_KEY][TRGT_KEY],\n",
    "                node_aliases[get_obj(item[ENTITY_KEY])]\n",
    "                + \".\"\n",
    "                + item[MAPPING_KEY][SRC_KEY],\n",
    "            )\n",
    "    for col in othercols:\n",
    "        if is_elem_aggregated(col):\n",
    "            src_trgt_map.setdefault(\n",
    "                col[NAME_KEY],\n",
    "                wrap_agg(all_join_nodes[col[NAME_KEY]], col[AGG_BEHAV_KEY]),\n",
    "            )\n",
    "        else:\n",
    "            src_trgt_map.setdefault(col[NAME_KEY], all_join_nodes[col[NAME_KEY]])\n",
    "    return src_trgt_map\n",
    "\n",
    "\n",
    "def filter_join_nodes(all_nodes):\n",
    "    join_nodes = list(\n",
    "        filter(\n",
    "            lambda x: isinstance(x, dict)\n",
    "            and x.get(XSITYP_KEY, \"\") == \"Calculation:JoinView\",\n",
    "            all_nodes[\"calculationView\"],\n",
    "        )\n",
    "    )\n",
    "    join_nodes_final = []\n",
    "    for node in join_nodes:\n",
    "        if is_list(node):\n",
    "            if any([JOINTYP_KEY in join for join in node[\"join\"]]):\n",
    "                join_list = list(filter(lambda x: JOINTYP_KEY in x, node[\"join\"]))\n",
    "                node[\"join\"] = join_list\n",
    "                join_nodes_final.append(node)\n",
    "        else:\n",
    "            if JOINTYP_KEY in node:\n",
    "                join_nodes_final.append(node)\n",
    "    return join_nodes_final\n",
    "\n",
    "\n",
    "def projection_qry_extract(projection_nodes):\n",
    "    queries = dict()\n",
    "    for i, node in enumerate(projection_nodes):\n",
    "        from_part = get_from_part(node[INPUT_KEY])\n",
    "        where_part = get_filter_exp(node)\n",
    "        from_with_filter = from_part + \"\\n\" + where_part\n",
    "        col_dict = {x[TRGT_KEY]: x[SRC_KEY] for x in node[INPUT_KEY][MAPPING_KEY]}\n",
    "        columns = get_cols_from_map(\n",
    "            col_dict\n",
    "        )  #   [ x[SRC_KEY]+ ' ' + x[TRGT_KEY] for x in node[INPUT_KEY][MAPPING_KEY]  ]\n",
    "        if node[\"calculatedViewAttributes\"] is not None:\n",
    "            calc_col_map = get_calc_columns(node[\"calculatedViewAttributes\"])\n",
    "            calc_cols = get_calc_cols_from_map(calc_col_map)\n",
    "            columns.extend(calc_cols)\n",
    "        select_part = SELECT_STR + \", \".join(columns) + \"\\n\"\n",
    "        full_query = newline_beatify(repl_sap_func(select_part + from_with_filter))\n",
    "        queries[node[\"@id\"]] = {\"query\": full_query, \"pos\": int(i)}\n",
    "    all_queries.update(queries)\n",
    "\n",
    "\n",
    "def aggregation_qry_extract(aggregation_nodes):\n",
    "    queries = dict()\n",
    "    for i, node in enumerate(aggregation_nodes):\n",
    "        from_part = get_from_part(node[INPUT_KEY])\n",
    "        where_part = get_filter_exp(node)\n",
    "        from_with_filter = from_part + \"\\n\" + where_part\n",
    "        final_cols = dict()\n",
    "        group_by_part = GROUP_STR\n",
    "        source_target_mapping = dict()\n",
    "        if not isinstance(node[INPUT_KEY][MAPPING_KEY], list):\n",
    "            source_target_mapping.update(\n",
    "                {\n",
    "                    node[INPUT_KEY][MAPPING_KEY][TRGT_KEY]: node[INPUT_KEY][\n",
    "                        MAPPING_KEY\n",
    "                    ][SRC_KEY]\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            source_target_mapping.update(\n",
    "                {x[TRGT_KEY]: x[SRC_KEY] for x in node[INPUT_KEY][MAPPING_KEY]}\n",
    "            )\n",
    "        if (\n",
    "            isinstance(node[ELEM_KEY][\"viewAttribute\"], list)\n",
    "            or len(node[ELEM_KEY][\"viewAttribute\"]) == 1\n",
    "        ):\n",
    "            if isinstance(node[ELEM_KEY][\"viewAttribute\"], dict):\n",
    "                if node[ELEM_KEY][\"viewAttribute\"][NAME_KEY] in source_target_mapping:\n",
    "                    final_cols[\n",
    "                        node[ELEM_KEY][\"viewAttribute\"][NAME_KEY]\n",
    "                    ] = source_target_mapping[node[ELEM_KEY][\"viewAttribute\"][NAME_KEY]]\n",
    "                else:\n",
    "                    final_cols[node[ELEM_KEY][\"viewAttribute\"][NAME_KEY]] = (\n",
    "                        node[ELEM_KEY][\"viewAttribute\"][CALC_KEY][FORMULA_KEY]\n",
    "                        if is_num_type(node[ELEM_KEY][\"viewAttribute\"])\n",
    "                        else node[ELEM_KEY][\"viewAttribute\"][CALC_KEY][\n",
    "                            FORMULA_KEY\n",
    "                        ].replace(\"+\", \" || \")\n",
    "                    )                   \n",
    "            else:\n",
    "                for x in node[ELEM_KEY][\"viewAttribute\"]:\n",
    "                    if x[NAME_KEY] in source_target_mapping:\n",
    "                        final_cols[x[NAME_KEY]] = source_target_mapping[x[NAME_KEY]]\n",
    "                    else:\n",
    "                        final_cols[x[NAME_KEY]] = (\n",
    "                            x[CALC_KEY][FORMULA_KEY]\n",
    "                            if is_num_type(x)\n",
    "                            else x[CALC_KEY][FORMULA_KEY].replace(\"+\", \" || \")\n",
    "                        )\n",
    "                    final_cols[x[NAME_KEY]] = (\n",
    "                        wrap_agg(final_cols[x[NAME_KEY]], x[AGG_BEHAV_KEY])\n",
    "                        if is_elem_aggregated(x)\n",
    "                        else final_cols[x[NAME_KEY]]\n",
    "                    )\n",
    "        else:\n",
    "            final_cols[node[ELEM_KEY][\"viewAttribute\"][NAME_KEY]] = (\n",
    "                source_target_mapping[node[ELEM_KEY][\"viewAttribute\"][NAME_KEY]]\n",
    "                if node[ELEM_KEY][\"viewAttribute\"][NAME_KEY] in source_target_mapping\n",
    "                else None\n",
    "            )\n",
    "            final_cols[node[ELEM_KEY][\"viewAttribute\"][NAME_KEY]] = (\n",
    "                wrap_agg(\n",
    "                    final_cols[node[ELEM_KEY][\"viewAttribute\"][NAME_KEY]],\n",
    "                    node[ELEM_KEY][\"viewAttribute\"][AGG_BEHAV_KEY],\n",
    "                )\n",
    "                if is_elem_aggregated(node[ELEM_KEY][\"viewAttribute\"])\n",
    "                else final_cols[node[ELEM_KEY][\"viewAttribute\"][NAME_KEY]]\n",
    "            )\n",
    "        \n",
    "        if node[CALCS_KEY] is not None and CALC_KEY in node[CALCS_KEY] and node[CALCS_KEY][CALC_KEY] is not None and isinstance(node[CALCS_KEY][CALC_KEY], dict) and len(node[CALCS_KEY][CALC_KEY]) in (4,5) and node[CALCS_KEY][CALC_KEY][NAME_KEY] not in final_cols:\n",
    "            final_cols[node[CALCS_KEY][CALC_KEY][NAME_KEY]] = (\n",
    "                        node[CALCS_KEY][CALC_KEY][FORMULA_KEY].replace('\"', '') + \"::\" + node[CALCS_KEY][CALC_KEY][DATATYPE_KEY] + ' AS '\n",
    "                        if is_num_type(node[CALCS_KEY][CALC_KEY])\n",
    "                        else node[CALCS_KEY][CALC_KEY][FORMULA_KEY]\n",
    "                        .replace(\"+\", \" || \")\n",
    "                        )\n",
    "        elif node[CALCS_KEY] is not None and CALC_KEY in node[CALCS_KEY] and node[CALCS_KEY][CALC_KEY] is not None and isinstance(node[CALCS_KEY][CALC_KEY], dict) and node[CALCS_KEY][CALC_KEY][NAME_KEY] not in final_cols:\n",
    "            try:\n",
    "                for x in node[CALCS_KEY][CALC_KEY]:\n",
    "                    \n",
    "                        final_cols[x[NAME_KEY]] = (\n",
    "                            x[FORMULA_KEY].replace('\"', '') + \"::\" + x[DATATYPE_KEY] + ' AS ' \n",
    "                            if isinstance(x, dict) and is_num_type(x)\n",
    "                            else\n",
    "                            x[FORMULA_KEY]\n",
    "                            .replace(\"+\", \" || \")\n",
    "                            )\n",
    "            except:\n",
    "                final_cols[node[CALCS_KEY][CALC_KEY][NAME_KEY]] = (node[CALCS_KEY][CALC_KEY][FORMULA_KEY].replace(\"+\", \" || \"))\n",
    "\n",
    "         \n",
    "        select_cols = get_cols_from_map(final_cols)    \n",
    "        select_part = SELECT_STR + \", \".join(select_cols)\n",
    "        \n",
    "        full_query = newline_beatify(\n",
    "            repl_sap_func(select_part + \"\\n\" + from_with_filter + \"\\n\" + group_by_part)\n",
    "        )\n",
    "        \n",
    "        queries[node[NAME_KEY]] = {\"query\": full_query, \"pos\": int(i)}\n",
    "    all_queries.update(queries)\n",
    "\n",
    "\n",
    "def join_qry_extract(join_nodes):\n",
    "    queries = dict()\n",
    "    for i, node in enumerate(join_nodes):\n",
    "        agg_elements = set(\n",
    "            [\n",
    "                x[AGG_BEHAV_KEY]\n",
    "                for x in node[ELEM_KEY][\"viewAttribute\"]\n",
    "                if is_elem_aggregated(x)\n",
    "            ]\n",
    "        )\n",
    "        where_part = get_filter_exp(node)\n",
    "        group_by_part = \"\"\n",
    "        if any(agg_elements):\n",
    "            group_by_part = GROUP_STR\n",
    "        full_join = generate_full_join(node, node_name=node[NAME_KEY])\n",
    "        other_columns = [\n",
    "            x for x in node[ELEM_KEY][\"viewAttribute\"] if not is_calc_col(x)\n",
    "        ]\n",
    "        other_col_map = get_other_colmap(node, other_columns, node[NAME_KEY])\n",
    "        calculated_colmap = (\n",
    "            get_calc_columns(node[\"calculatedViewAttributes\"])\n",
    "            if is_calc_col(node[\"calculatedViewAttributes\"])\n",
    "            else {}\n",
    "        )\n",
    "        calculated_colmap = get_calc_cols_from_map(calculated_colmap, True)\n",
    "        source_target_mapping = dict()\n",
    "        source_target_mapping.update(other_col_map)\n",
    "        source_target_mapping.update(calculated_colmap)\n",
    "        select_cols = get_cols_from_map(source_target_mapping, fromnode=\"JoinNode\")\n",
    "        select_qry = SELECT_STR + \", \".join(select_cols)\n",
    "        full_query = repl_sap_func(\n",
    "            select_qry + \"\\n\" + full_join + \"\\n\" + where_part + \"\\n\" + group_by_part\n",
    "        )\n",
    "        other_col_map = {\"`\" + k + \"`\": v for k, v in other_col_map.items()}\n",
    "        full_query = newline_beatify(\n",
    "            replace_dict(query=full_query, rep_dict=other_col_map)\n",
    "        )\n",
    "        queries[node[NAME_KEY]] = {\"query\": full_query, \"pos\": int(i)}\n",
    "        \n",
    "    all_queries.update(queries)\n",
    "\n",
    "\n",
    "def rank_qry_extract(rank_nodes):\n",
    "    queries = dict()\n",
    "    for i, node in enumerate(rank_nodes):\n",
    "        all_cols = [x[NAME_KEY] for x in node[ELEM_KEY][\"viewAttribute\"]]\n",
    "        from_part = get_from_part(node[INPUT_KEY])\n",
    "        input_mapping = node[INPUT_KEY][MAPPING_KEY]\n",
    "        source_target_mapping = {}\n",
    "        if isinstance(input_mapping, list):\n",
    "            source_target_mapping = {x[TRGT_KEY]: x[SRC_KEY] for x in input_mapping}\n",
    "        else:\n",
    "            source_target_mapping.update(\n",
    "                {input_mapping[TRGT_KEY]: input_mapping[SRC_KEY]}\n",
    "            )\n",
    "        partition = node[\"windowFunction\"][\"partitionViewAttributeName\"]\n",
    "        partitionby_part = (\n",
    "            \"PARTITION BY \" + \",\".join(partition)\n",
    "            if not isinstance(partition, str)\n",
    "            else \"PARTITION BY \" + partition\n",
    "        ) \n",
    "        order = node[\"windowFunction\"][\"order\"]\n",
    "        rank_threshold = node[\"windowFunction\"][\"rankThreshold\"][\"value\"]\n",
    "        orderby_cols = []\n",
    "        orderby_part = \" ORDER BY \"\n",
    "        if isinstance(order, list):\n",
    "            orderby_cols = [\n",
    "                x[\"@byViewAttributeName\"] + \" \" + x[\"@direction\"] for x in order\n",
    "            ]\n",
    "        else:\n",
    "            orderby_cols.append(\n",
    "                order[\"@byViewAttributeName\"] + \" \" + order[\"@direction\"]\n",
    "            )\n",
    "        orderby_part = (\n",
    "            orderby_part + \", \".join(orderby_cols)\n",
    "            if not isinstance(orderby_cols, str)\n",
    "            else orderby_part + orderby_cols\n",
    "        )\n",
    "        rank_part = \"RANK() OVER (\" + partitionby_part + orderby_part + \")\"\n",
    "        rank_col = list(filter(lambda x: x not in source_target_mapping, all_cols))\n",
    "        if len(rank_col) == 0:\n",
    "            rank_col.append('r1')\n",
    "            rank_col = rank_col[0]\n",
    "        where_part = \"WHERE \" + str(rank_col) + \"= \" + rank_threshold\n",
    "        from_with_filter = from_part + \"\\n\" + where_part\n",
    "        source_target_mapping[rank_col] = rank_part\n",
    "        all_cols = get_cols_from_map(source_target_mapping)\n",
    "        select_part = SELECT_STR + \", \".join(all_cols)\n",
    "        full_query = newline_beatify(\n",
    "            repl_sap_func(select_part + \"\\n\" + from_with_filter) \n",
    "        )\n",
    "        queries[node[NAME_KEY]] = {\"query\": full_query, \"pos\": int(i)}\n",
    "    all_queries.update(queries)\n",
    "\n",
    "\n",
    "def union_qry_extract(union_nodes):\n",
    "    queries = dict()\n",
    "    for i, node in enumerate(union_nodes):\n",
    "        from_objects = node[INPUT_KEY]\n",
    "        from_mapping = []\n",
    "        from_object_names = []\n",
    "        select_qrys = []\n",
    "        source_target_mapping = {}\n",
    "        for i in range(len(from_objects)):\n",
    "            from_object_names.append(get_from_part(from_objects[i]))\n",
    "            from_mapping = from_objects[i][MAPPING_KEY]\n",
    "            for x in from_mapping:\n",
    "                if x[XSITYP_KEY] == \"Calculation:AttributeMapping\":\n",
    "                    source_target_mapping[x[TRGT_KEY]] = x[SRC_KEY]\n",
    "                else:\n",
    "                    source_target_mapping[x[TRGT_KEY]] = \"NULL AS\"\n",
    "            select_part = SELECT_STR + \", \".join(\n",
    "                get_cols_from_map(source_target_mapping)\n",
    "            )\n",
    "            select_qrys.append(select_part)\n",
    "        full_qrys = get_cols_from_map(dict(zip(from_object_names, select_qrys)))\n",
    "        full_query = newline_beatify(repl_sap_func(\"\\n\\nUNION ALL\\n\\n\".join(full_qrys)))\n",
    "        queries[node[NAME_KEY]] = {\"query\": full_query, \"pos\": int(i)}\n",
    "    all_queries.update(queries)\n",
    "\n",
    "\n",
    "def main():\n",
    "    shutil.rmtree(\"queries\", ignore_errors=True)\n",
    "    Path(\"queries\").mkdir(parents=True, exist_ok=True)\n",
    "    for subdir, _, files in os.walk(\"xmls/\"):\n",
    "        for file in files:\n",
    "            XML_FILE = subdir + file\n",
    "            SQL_FILE = \"queries/\" + XML_FILE.split(\"/\")[-1].split(\".\")[0]\n",
    "            with open(XML_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "                my_xml = file.read()\n",
    "                all_queries.clear()\n",
    "            \n",
    "            # try:\n",
    "            print(f\"{SQL_FILE}.sql creation has been started\")\n",
    "            global full_xml_nodes\n",
    "            full_xml_nodes = dict(xmltodict.parse(my_xml))[\"Calculation:scenario\"]\n",
    "            all_nodes = dict(xmltodict.parse(my_xml))[\"Calculation:scenario\"][\n",
    "                \"calculationViews\"\n",
    "            ]\n",
    "\n",
    "            projection_nodes = list(\n",
    "                filter(\n",
    "                    lambda x: isinstance(x, dict)\n",
    "                    and x.get(XSITYP_KEY, \"\") == \"Calculation:ProjectionView\",\n",
    "                    all_nodes[\"calculationView\"],\n",
    "                )\n",
    "            )\n",
    "            aggregation_nodes = list(\n",
    "                filter(\n",
    "                    lambda x: isinstance(x, dict)\n",
    "                    and x.get(XSITYP_KEY, \"\") == \"Calculation:AggregationView\",\n",
    "                    all_nodes[\"calculationView\"],\n",
    "                )\n",
    "            )\n",
    "            join_nodes = filter_join_nodes(all_nodes)\n",
    "            rank_nodes = list(\n",
    "                filter(\n",
    "                    lambda x: isinstance(x, dict)\n",
    "                    and x.get(XSITYP_KEY, \"\") == \"Calculation:RankView\",\n",
    "                    all_nodes[\"calculationView\"],\n",
    "                )\n",
    "            )\n",
    "            union_nodes = list(\n",
    "                filter(\n",
    "                    lambda x: isinstance(x, dict)\n",
    "                    and x.get(XSITYP_KEY, \"\") == \"Calculation:UnionView\",\n",
    "                    all_nodes[\"calculationView\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            projection_qry_extract(projection_nodes)\n",
    "            aggregation_qry_extract(aggregation_nodes)\n",
    "            join_qry_extract(join_nodes)\n",
    "            rank_qry_extract(rank_nodes)\n",
    "            union_qry_extract(union_nodes)\n",
    "\n",
    "            all_queries_sorted = OrderedDict(\n",
    "                sorted(all_queries.items(), key=lambda x: x[1][\"pos\"], reverse=True)\n",
    "            )\n",
    "            \n",
    "\n",
    "            with open(f\"{SQL_FILE}.sql\", \"w\", newline=\"\") as f:\n",
    "                for k, v in all_queries_sorted.items():\n",
    "                    f.write(f\"create or replace temporary view {k.lower()} as (\\n\" \n",
    "                            + \n",
    "                            lower_except_quotes(v[\"query\"]).replace(\"\\\\'\", \"'\").replace('   ', ' ').replace('\\n\\n', '\\n').replace(\",\\nif\",', if').replace(\",\\n'\",\", '\").replace(\",\\n\\nif\",\",\\nif\").replace('\\n\\n\\n\\n', '\\n').replace('\\n\\n\\n', '\\n').replace('  ', ' ').replace(\"', \\n '\",\"', '\").replace(\", \\n \\nif\",\", if\").replace('\\n', ' ').replace('\\n ', ' ').replace('\\r ', ' ').replace(', \\n if', ', if').replace('   ', ' ').replace('   ', ' ').replace('   ', ' ').replace(',  ',',\\n').replace('in(','').replace(\"']\", \"\").replace(\"['\", \"\").replace(\"(),\",\"(\").replace(\"in () = \",\") =\").replace(\"in () =\",\") =\").replace(\"in () !=\",\") !=\").replace(\"() , \",\"(\").replace(\" in ()\",')').replace(\"to_int\",\"int\").replace(\"to_int\",\"int\")\n",
    "                            + \n",
    "                            \"\\n);\\n\"\n",
    "                    )\n",
    "                    \n",
    "            print(f\"{SQL_FILE}.sql file has been created\")\n",
    "            # except Exception as e:\n",
    "            #     print(f\"\\033[91m{XML_FILE} file has incorrect format: {str(e)}\\033[0m\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    print(\"Time taken (ms)=\", round((time.time() - start_time) * 1000))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "hana_xml_to_sql_utility",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
