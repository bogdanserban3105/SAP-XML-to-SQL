{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "153bbd8d-20e1-416a-905a-980270dd574a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# STEPS TO USE THIS NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0795f4d-34f2-47cf-9fbd-52180b16ae0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. GET GSCDCA-LPDAP-ADMPIM-DEM-BDT FROM [HERE](https://portal.azure.com/?Microsoft_Azure_PIMCommon=true&feature.msaljs=true#view/Microsoft_Azure_PIMCommon/ActivationMenuBlade/~/aadgroup/provider/aadgroup) (THIS RESETS AT DAILY BASIC, NEED TO REQUEST IT AGAIN AFTER 8 HOURS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "113567f7-d4b2-4695-8fa7-07f428e91de1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.START THE CLUSTER WITH YOUR NAME OR CHANGE THE CLUSTER OWNER FROM THE COMPUTE MENU\n",
    "### STEPS TO CHANGE CLUSTER OWNER\n",
    "### 2.1 ![Screenshot 2025-06-06 152220.png](./Screenshot 2025-06-06 152220.png \"Screenshot 2025-06-06 152220.png\")\n",
    "### 2.2 ![Screenshot 2025-06-06 152719.png](./Screenshot 2025-06-06 152719.png \"Screenshot 2025-06-06 152719.png\")\n",
    "### 2.3 ![Screenshot 2025-06-06 152829.png](./Screenshot 2025-06-06 152829.png \"Screenshot 2025-06-06 152829.png\")\n",
    "### 2.4 BACK TO THE NOTEBOOK AND NEXT TO RUN ALL IN THE RIGHT UPPER CORNER PRESS THE CLUSTER MAIN\n",
    "## THOSE STEPS NEED TO BE AT LEAST CHECKED BEFORE STARTING THE NOTEBOOK, IF NOT THE OWNER OF CLUSTER IT WILL CREATE ERRORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46021cda-bc8e-4ad3-bae1-f43edede7f99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.ON THE TOP OF THE NOTEBOOK YOU CAN SEE ALL PARAMETERS. \n",
    "3.1 USER is the name of the folder created on blob storage: for example :\n",
    "\n",
    "3.2 BASE__CHOISE is the subfolder of your _test folder: for example :\n",
    "\n",
    "3.3 FILE_TYPE IS THE FILE TYPE YOU WANT PROCESSED, IF YOU HAVE ONLY .TXT FILES INSIDE FILTER PICK TXT\n",
    "\n",
    "3.4 WANT_CLEAN_CODE IS A FLAG THAT, IF YOU PICK TRUE, IT WILL PROVIDE YOU 2 OUTPUTS, 1 WITH EXPLINATIONS AND THE OTHER ONE WITH JUST CODE\n",
    "\n",
    "3.5 PROVIDED_CONTEXT THIS IS WHERE YOU ADD YOUR PROMPT\n",
    "\n",
    "3.6 FILES THIS IS WHERE YOU SELECT WHICH FILES FROM THE FOLDER YOU WANT PROCESSED, IF YOU WANT ALL FILES SELECT \"ALL FILES\"\n",
    "\n",
    "3.7 MODEL_CHOICE THIS IS THE GPT MODEL, O1 PROVIDES BEST ANSWERS\n",
    "\n",
    "## PLEASE SELECT/UPDATE PARAMETERS IN ORDER FROM LEFT TO RIGHT FOR CORRECT VARIABLE APPENDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77cb636a-bee5-4732-8a77-827c4e4dd63c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4.AFTER COMPLETING THE PARAMETERES PRESS RUN ALL FROM UPPER RIGHT CORNER. THE OUTPUT WILL BE AVALIBLE IN THE LAST CELL AND ALSO ON BLOB STORAGE UNDER YOUR FOLDER, EX:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7142b432-d8a8-48f6-9f97-9308ef4f5efe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# AFTER YOU RUN THE WHOLE NOTEBOOK ONCE IT IS NOT NECECSARY TO RUN ALL AGAIN. IF YOU CHANGE THE INPUT PARAMETERS THEY WILL BE DINAMICALLY CHANGED. AFTER RUN ALL YOU CAN RUN ONLY THE LAST CELL, THERE IS A BLUE BUTTON ON THE LEFT UPPER CORNER OF THE CELL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "179c604d-ca1f-47ca-8896-34d731f02612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# IF YOU RECIEVE ANY ERROR, PLEASE REFRESH YOUR WEB BROWSER PAGE, IF ERROR PERSIST LOG OUT AND IN DATABRICKS. IF YOU CANNOT START YOUR CLUSTER VERIFY AGAIN IF YOU HAVE ADMIN ACCESS FROM THE GSCDCA-LPDAP-ADMPIM-DEM-BDT ROLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d62beb7a-55f5-47b3-ae06-893c13efc4a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "dbutils.fs.rm(\"dbfs:/tmp/\", True)\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7819c4f2-438b-4768-b357-fc468291f738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import time\n",
    "import shutil\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pyspark.sql import Row\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=\"PLACEHOLDER\",\n",
    "    api_key=\"PLACEHOLDER\",\n",
    ")\n",
    "\n",
    "client_v2 = AzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=\"PLACEHOLDER\",\n",
    "    api_key=\"PLACEHOLDER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "808f3475-7325-47f5-84f2-f7c74c4c70e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "   \n",
    "\n",
    "# Define the storage account and container name\n",
    "sa = \"stlpdel01dev\"\n",
    "container_name = \"codeconverter\" \n",
    "# Set Azure authentication configuration\n",
    "spark.conf.set(\"fs.azure.account.auth.type\", \"CustomAccessToken\")\n",
    "spark.conf.set(\"fs.azure.account.custom.token.provider.class\", spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\"))\n",
    "\n",
    "# Set the base URL for the container and directories\n",
    "base_url = f\"abfss://{container_name}@{sa}.dfs.core.windows.net/\"\n",
    "\n",
    "# Print the base URL for verification\n",
    "# print(base_url)\n",
    "\n",
    "# #asta trebuie pornit primul doar o singura data\n",
    "import certifi\n",
    "\n",
    "scope_name = \"OpenAI-scope\"\n",
    "secret_name = \"OpenAI-certificate\"\n",
    "\n",
    "secret_value = dbutils.secrets.get(scope=scope_name, key=secret_name)\n",
    "\n",
    "print(\"---- Retrieve CA ----\")\n",
    "ca_cert = certifi.where()\n",
    "print(\"---- Appending new SSL to CA ----\")\n",
    "\n",
    "with open(ca_cert, \"a\") as custom_certificate:\n",
    "    cert_content = custom_certificate.write(\"\\n# Custom appended certificate \\n\")\n",
    "    cert_content = custom_certificate.write(secret_value)\n",
    "    cert_content = custom_certificate.write(\"\\n\")\n",
    "\n",
    "print(f\"---- Successfully appended to: {ca_cert} ----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb529d42-3cfd-4c5e-9d4b-531e249a6177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a dropdown widget for selecting model type (o1 or o1 mini)\n",
    "dbutils.widgets.dropdown(\"model_choice\", \"o1\", [\"o1\", \"o1-mini\", \"o1-preview\",\"gpt-4o\"], \"Choose model type\")\n",
    "# Retrieve the selected model type\n",
    "selected_model = dbutils.widgets.get(\"model_choice\")\n",
    "print(f\"Selected model: {selected_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "477d0bed-7dc5-4936-8515-1bcaf1a27261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def callmodel4o(deployment_name, prompt):\n",
    "\n",
    "  start_phrase = prompt\n",
    "  response = client_v2.chat.completions.create(\n",
    "      model=deployment_name,  # This refers to the deployed model name (gpt-4o)\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a code converting specialist between SAP Code and Databricks code.\"},\n",
    "          {\"role\": \"user\", \"content\": start_phrase}\n",
    "      ],\n",
    "      max_tokens=10000,  # Set the maximum length of the response\n",
    "      temperature=0.2,  # Lower temperature for more deterministic responses\n",
    "      top_p=0.8,        # More standard responses\n",
    "      frequency_penalty=0.1, # Allow code repetition\n",
    "      presence_penalty=0.0 # Less varied content\n",
    "  )\n",
    "\n",
    "  #print(response)\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e6040a7-beef-4672-98b0-51f01120fb3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def callmodelo1(deployment_name, prompt):\n",
    "\n",
    "  start_phrase = prompt\n",
    "  response = client_v2.chat.completions.create(\n",
    "      model=deployment_name,  # This refers to the deployed model name (gpt-4o)\n",
    "      messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": start_phrase\n",
    "        }\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  #print(response)\n",
    "  return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f2ed2e5-da85-4330-a348-04c9f5fad783",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_model_o1(deployment_name, prompt, context):\n",
    "    # Define the start phrase as the user input (XML configuration and prompt)\n",
    "    start_phrase = prompt  # The prompt you want to send to the model\n",
    "\n",
    "    # Define the system message that provides the context\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": context\n",
    "        }\n",
    "\n",
    "    # Make the API call to get the response from the model\n",
    "    response = client_v2.chat.completions.create(\n",
    "        model=deployment_name,  # The name of your deployed model (e.g., gpt-4-deployment)\n",
    "        messages=[\n",
    "            system_message,  # Add the system message to set the context\n",
    "            {\n",
    "                \"role\": \"user\",  # User is sending the message\n",
    "                \"content\": start_phrase  # The actual prompt content (XML configuration)\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content  # Return the model's response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f07e6347-64a0-4b2f-a286-00ca08d46e75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_model(selected_model, prompt, context):\n",
    "    if selected_model == \"o1\":\n",
    "        return call_model_o1(deployment_name=\"o1\", prompt=prompt, context=context)  # Call the o1 model function\n",
    "    elif selected_model == \"o1-preview\":\n",
    "        return callmodelo1(deployment_name=\"o1-preview\", prompt=prompt)  # Call the o1-preview model function\n",
    "    elif selected_model == \"o1-mini\":\n",
    "        return callmodelo1(deployment_name=\"o1-mini\", prompt=prompt)  # Call the o1-mini model function\n",
    "    elif selected_model == 'gpt-4o':\n",
    "        return callmodel4o(deployment_name=\"gpt-4o\", prompt=prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56796336-b588-4d8d-b52f-3414c08ca8d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaning_context = \"\"\"You are an expert in converting SAP logic, represented in XML configuration, into Databricks SQL.\n",
    "                   Your task is to parse the logic in the XML and generate the corresponding Databricks SQL queries.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd1cb63c-dddc-46f8-9695-d2fc6c53c845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# CHANGE THE VARIABLE BELOW TO CHANGE THE PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a16cf645-9f67-4ba3-898e-5a1277f7aeed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"Correct the SQL code below and optimize it with the best practices of Databricks. Check that the if syntax is correct and there is no character missing, remove the formatting and standardize the syntax.Use lowercase for statements and use new line for every column name or statement.Be sure to not change filters. Put the select between () and use ; at the end and a new line. Be sure to replace syntax to syntax compatible with databricks: for example: in(\"vz_cd_pa\",'70','71') -> vz_cd_pa in ('70','71'). Be sure that all the paranthesys opened are closed and no extra are added. Be sure to not change the order of the columns. Output only the code reviewed and corrected.\n",
    " \n",
    "SQL code:\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaaeb749-8921-448f-956a-164bd32069ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_parameters(files):\n",
    "    subdir = \"queries/\"\n",
    "    SQL_FILE = subdir + files\n",
    "    GPT_FILE = \"GPT_OutPut/\" + SQL_FILE.split(\"/\")[-1].split(\".\")[0]\n",
    "    with open(SQL_FILE, \"r\", encoding=\"utf-8\") as files:\n",
    "        my_sql = files.read()\n",
    "    prompt = my_sql\n",
    "    RowList = [Row(col) for col in prompt.split(';') if col.replace('\\n', '').replace(\" \", \"\") != '']; \n",
    "    RowList = spark.createDataFrame(RowList).withColumnRenamed(\"_1\", \"table_statement\")\n",
    "    return GPT_FILE,prompt,RowList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9223136a-28ab-4990-ab83-716ae85bf0b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed  \n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "def chat_gpt(input):\n",
    "    statements, GPT_FILE = input[\"statements\"], input[\"GPT_FILE\"]\n",
    "    prompt_single_table = statements.replace('\\n','')\n",
    "    table_name = prompt_single_table.split(\"as (\")[0].replace('create or replace temporary view ', '').replace('  ', '')\n",
    "    table_path = GPT_FILE\n",
    "    prompt = prompt_single_table\n",
    "    if (word in prompt_single_table.lower() for word in ('if','case','join','rank','union')):\n",
    "        try:\n",
    "            model_output = call_model(selected_model, prompt=prompt, context=instruction)\n",
    "            with open(f\"{GPT_FILE}.sql\", \"a\", newline=\"\") as c:\n",
    "                c.write(f\"\\n\\n\" + model_output)\n",
    "        except:\n",
    "            model_output = statements\n",
    "            with open(f\"{GPT_FILE}.sql\", \"a\", newline=\"\") as c:\n",
    "                c.write(f\"\\n\\n NOT_MODIFIED \\n\\n\" + model_output)\n",
    "            \n",
    "    else:\n",
    "        model_output = statements\n",
    "        with open(f\"{GPT_FILE}.sql\", \"a\", newline=\"\") as c:\n",
    "            c.write(f\"\\n\\n ONLY_SELECT \\n\\n\" + model_output)\n",
    "\n",
    "files = os.listdir(\"queries/\")\n",
    "for file in files:\n",
    "    GPT_FILE,prompt,RowList = get_parameters(file)\n",
    "    input = [{\"statements\": statement, \"GPT_FILE\": GPT_FILE} for statement in RowList.select(\"table_statement\").rdd.flatMap(lambda x: x).collect()]\n",
    "    progress = 0\n",
    "    max_progress = len(input)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_file = executor.map(chat_gpt, input)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "bc875105-953b-4a0f-89ae-a91cb4012006",
     "origId": 1914346916401682,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": {
    "autoRunOnWidgetChange": "auto-run-selected-command"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4,
    "widgetLayout": [
     {
      "breakBefore": false,
      "name": "User",
      "width": 170
     },
     {
      "breakBefore": false,
      "name": "Base_choise",
      "width": 170
     },
     {
      "breakBefore": false,
      "name": "file_type",
      "width": 170
     },
     {
      "breakBefore": false,
      "name": "want_clean_code",
      "width": 170
     },
     {
      "breakBefore": false,
      "name": "files",
      "width": 310
     },
     {
      "breakBefore": false,
      "name": "model_choice",
      "width": 170
     }
    ]
   },
   "notebookName": "ChatGPT",
   "widgets": {
    "model_choice": {
     "currentValue": "o1",
     "nuid": "0a8064ef-e38f-4a31-9921-515fbeba07a7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "o1",
      "label": "Choose model type",
      "name": "model_choice",
      "options": {
       "choices": [
        "o1",
        "o1-mini",
        "o1-preview",
        "gpt-4o"
       ],
       "fixedDomain": true,
       "multiselect": false,
       "widgetDisplayType": "Dropdown"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "o1",
      "label": "Choose model type",
      "name": "model_choice",
      "options": {
       "autoCreated": null,
       "choices": [
        "o1",
        "o1-mini",
        "o1-preview",
        "gpt-4o"
       ],
       "widgetType": "dropdown"
      },
      "widgetType": "dropdown"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
